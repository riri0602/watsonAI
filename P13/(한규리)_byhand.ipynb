{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o176gKn3yL-O"
   },
   "source": [
    "# P13-1 실습 과제\n",
    "##Mini-batch size & Learning Rate 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "achHRPhwHPF3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 500 samples\n",
      "Epoch 1/150\n",
      "500/500 - 7s - loss: 2.7510 - accuracy: 0.3580 - val_loss: 1.7969 - val_accuracy: 0.5620\n",
      "Epoch 2/150\n",
      "500/500 - 6s - loss: 1.6243 - accuracy: 0.5740 - val_loss: 1.1117 - val_accuracy: 0.6940\n",
      "Epoch 3/150\n",
      "500/500 - 7s - loss: 1.2562 - accuracy: 0.6280 - val_loss: 0.9803 - val_accuracy: 0.6520\n",
      "Epoch 4/150\n",
      "500/500 - 6s - loss: 1.0067 - accuracy: 0.5980 - val_loss: 0.9554 - val_accuracy: 0.6180\n",
      "Epoch 5/150\n",
      "500/500 - 6s - loss: 0.9277 - accuracy: 0.6360 - val_loss: 0.6905 - val_accuracy: 0.6960\n",
      "Epoch 6/150\n",
      "500/500 - 6s - loss: 0.7429 - accuracy: 0.6660 - val_loss: 0.7723 - val_accuracy: 0.6760\n",
      "Epoch 7/150\n",
      "500/500 - 6s - loss: 0.8056 - accuracy: 0.6460 - val_loss: 0.5872 - val_accuracy: 0.7260\n",
      "Epoch 8/150\n",
      "500/500 - 7s - loss: 0.6903 - accuracy: 0.6840 - val_loss: 0.6184 - val_accuracy: 0.7880\n",
      "Epoch 9/150\n",
      "500/500 - 7s - loss: 0.7824 - accuracy: 0.6420 - val_loss: 0.8829 - val_accuracy: 0.7020\n",
      "Epoch 10/150\n",
      "500/500 - 6s - loss: 1.0049 - accuracy: 0.6160 - val_loss: 0.6726 - val_accuracy: 0.7420\n",
      "Epoch 11/150\n",
      "500/500 - 6s - loss: 0.8410 - accuracy: 0.6580 - val_loss: 0.6122 - val_accuracy: 0.7300\n",
      "Epoch 12/150\n",
      "500/500 - 7s - loss: 0.6540 - accuracy: 0.7120 - val_loss: 0.5437 - val_accuracy: 0.7320\n",
      "Epoch 13/150\n",
      "500/500 - 7s - loss: 0.6696 - accuracy: 0.6880 - val_loss: 0.6607 - val_accuracy: 0.7360\n",
      "Epoch 14/150\n",
      "500/500 - 6s - loss: 0.7523 - accuracy: 0.6860 - val_loss: 0.5761 - val_accuracy: 0.7560\n",
      "Epoch 15/150\n",
      "500/500 - 6s - loss: 0.7890 - accuracy: 0.6460 - val_loss: 0.5832 - val_accuracy: 0.7580\n",
      "Epoch 16/150\n",
      "500/500 - 6s - loss: 0.7880 - accuracy: 0.6820 - val_loss: 0.6283 - val_accuracy: 0.6880\n",
      "Epoch 17/150\n",
      "500/500 - 6s - loss: 0.5732 - accuracy: 0.7180 - val_loss: 0.5194 - val_accuracy: 0.8060\n",
      "Epoch 18/150\n",
      "500/500 - 6s - loss: 0.6699 - accuracy: 0.6980 - val_loss: 0.7416 - val_accuracy: 0.7220\n",
      "Epoch 19/150\n",
      "500/500 - 6s - loss: 0.6771 - accuracy: 0.7060 - val_loss: 0.5214 - val_accuracy: 0.8180\n",
      "Epoch 20/150\n",
      "500/500 - 6s - loss: 0.6205 - accuracy: 0.7360 - val_loss: 0.5238 - val_accuracy: 0.7700\n",
      "Epoch 21/150\n",
      "500/500 - 6s - loss: 0.5966 - accuracy: 0.7520 - val_loss: 0.4762 - val_accuracy: 0.8020\n",
      "Epoch 22/150\n",
      "500/500 - 7s - loss: 0.5007 - accuracy: 0.7900 - val_loss: 0.5326 - val_accuracy: 0.7900\n",
      "Epoch 23/150\n",
      "500/500 - 7s - loss: 0.5447 - accuracy: 0.7640 - val_loss: 0.4540 - val_accuracy: 0.8120\n",
      "Epoch 24/150\n",
      "500/500 - 6s - loss: 0.4786 - accuracy: 0.7880 - val_loss: 0.4841 - val_accuracy: 0.7920\n",
      "Epoch 25/150\n",
      "500/500 - 6s - loss: 0.4892 - accuracy: 0.7800 - val_loss: 0.4640 - val_accuracy: 0.8060\n",
      "Epoch 26/150\n",
      "500/500 - 6s - loss: 0.4889 - accuracy: 0.7800 - val_loss: 0.4747 - val_accuracy: 0.8120\n",
      "Epoch 27/150\n",
      "500/500 - 6s - loss: 0.4984 - accuracy: 0.7780 - val_loss: 0.4629 - val_accuracy: 0.8140\n",
      "Epoch 28/150\n",
      "500/500 - 7s - loss: 0.4926 - accuracy: 0.7900 - val_loss: 0.4966 - val_accuracy: 0.7920\n",
      "Epoch 29/150\n",
      "500/500 - 6s - loss: 0.5026 - accuracy: 0.7800 - val_loss: 0.4507 - val_accuracy: 0.8080\n",
      "Epoch 30/150\n",
      "500/500 - 7s - loss: 0.4689 - accuracy: 0.8020 - val_loss: 0.5946 - val_accuracy: 0.7340\n",
      "Epoch 31/150\n",
      "500/500 - 7s - loss: 0.5205 - accuracy: 0.7620 - val_loss: 0.5831 - val_accuracy: 0.7640\n",
      "Epoch 32/150\n",
      "500/500 - 6s - loss: 0.6077 - accuracy: 0.7200 - val_loss: 0.4914 - val_accuracy: 0.7840\n",
      "Epoch 33/150\n",
      "500/500 - 6s - loss: 0.5465 - accuracy: 0.7660 - val_loss: 0.4776 - val_accuracy: 0.7980\n",
      "Epoch 34/150\n",
      "500/500 - 6s - loss: 0.4679 - accuracy: 0.8060 - val_loss: 0.4312 - val_accuracy: 0.8280\n",
      "Epoch 35/150\n",
      "500/500 - 6s - loss: 0.4584 - accuracy: 0.8060 - val_loss: 0.4298 - val_accuracy: 0.8200\n",
      "Epoch 36/150\n",
      "500/500 - 6s - loss: 0.4741 - accuracy: 0.8040 - val_loss: 0.4651 - val_accuracy: 0.8160\n",
      "Epoch 37/150\n",
      "500/500 - 6s - loss: 0.5105 - accuracy: 0.7820 - val_loss: 0.5451 - val_accuracy: 0.7920\n",
      "Epoch 38/150\n",
      "500/500 - 6s - loss: 0.4568 - accuracy: 0.8140 - val_loss: 0.4189 - val_accuracy: 0.8320\n",
      "Epoch 39/150\n",
      "500/500 - 6s - loss: 0.4399 - accuracy: 0.8260 - val_loss: 0.4267 - val_accuracy: 0.8240\n",
      "Epoch 40/150\n",
      "500/500 - 7s - loss: 0.4404 - accuracy: 0.8200 - val_loss: 0.4307 - val_accuracy: 0.8180\n",
      "Epoch 41/150\n",
      "500/500 - 7s - loss: 0.4654 - accuracy: 0.8000 - val_loss: 0.4057 - val_accuracy: 0.8420\n",
      "Epoch 42/150\n",
      "500/500 - 6s - loss: 0.4438 - accuracy: 0.8140 - val_loss: 0.4244 - val_accuracy: 0.8220\n",
      "Epoch 43/150\n",
      "500/500 - 6s - loss: 0.4209 - accuracy: 0.8220 - val_loss: 0.4049 - val_accuracy: 0.8420\n",
      "Epoch 44/150\n",
      "500/500 - 6s - loss: 0.4290 - accuracy: 0.8160 - val_loss: 0.4109 - val_accuracy: 0.8320\n",
      "Epoch 45/150\n",
      "500/500 - 5s - loss: 0.4164 - accuracy: 0.8260 - val_loss: 0.4049 - val_accuracy: 0.8300\n",
      "Epoch 46/150\n",
      "500/500 - 6s - loss: 0.4148 - accuracy: 0.8340 - val_loss: 0.4071 - val_accuracy: 0.8380\n",
      "Epoch 47/150\n",
      "500/500 - 6s - loss: 0.4228 - accuracy: 0.8200 - val_loss: 0.4115 - val_accuracy: 0.8280\n",
      "Epoch 48/150\n",
      "500/500 - 6s - loss: 0.4254 - accuracy: 0.8260 - val_loss: 0.4354 - val_accuracy: 0.8200\n",
      "Epoch 49/150\n",
      "500/500 - 5s - loss: 0.4474 - accuracy: 0.8040 - val_loss: 0.4753 - val_accuracy: 0.8140\n",
      "Epoch 50/150\n",
      "500/500 - 6s - loss: 0.5576 - accuracy: 0.7580 - val_loss: 0.4263 - val_accuracy: 0.8220\n",
      "Epoch 51/150\n",
      "500/500 - 5s - loss: 0.5056 - accuracy: 0.7940 - val_loss: 0.4418 - val_accuracy: 0.8260\n",
      "Epoch 52/150\n",
      "500/500 - 6s - loss: 0.4564 - accuracy: 0.8000 - val_loss: 0.4205 - val_accuracy: 0.8240\n",
      "Epoch 53/150\n",
      "500/500 - 6s - loss: 0.4348 - accuracy: 0.8140 - val_loss: 0.4177 - val_accuracy: 0.8240\n",
      "Epoch 54/150\n",
      "500/500 - 7s - loss: 0.4141 - accuracy: 0.8180 - val_loss: 0.4042 - val_accuracy: 0.8280\n",
      "Epoch 55/150\n",
      "500/500 - 6s - loss: 0.4041 - accuracy: 0.8200 - val_loss: 0.4071 - val_accuracy: 0.8300\n",
      "Epoch 56/150\n",
      "500/500 - 6s - loss: 0.4130 - accuracy: 0.8180 - val_loss: 0.4026 - val_accuracy: 0.8240\n",
      "Epoch 57/150\n",
      "500/500 - 6s - loss: 0.4197 - accuracy: 0.8160 - val_loss: 0.4028 - val_accuracy: 0.8360\n",
      "Epoch 58/150\n",
      "500/500 - 6s - loss: 0.4434 - accuracy: 0.8160 - val_loss: 0.5606 - val_accuracy: 0.7500\n",
      "Epoch 59/150\n",
      "500/500 - 6s - loss: 0.5205 - accuracy: 0.7960 - val_loss: 0.4443 - val_accuracy: 0.8280\n",
      "Epoch 60/150\n",
      "500/500 - 7s - loss: 0.4380 - accuracy: 0.8080 - val_loss: 0.4052 - val_accuracy: 0.8220\n",
      "Epoch 61/150\n",
      "500/500 - 7s - loss: 0.4291 - accuracy: 0.8200 - val_loss: 0.4099 - val_accuracy: 0.8260\n",
      "Epoch 62/150\n",
      "500/500 - 7s - loss: 0.4318 - accuracy: 0.8100 - val_loss: 0.4032 - val_accuracy: 0.8360\n",
      "Epoch 63/150\n",
      "500/500 - 7s - loss: 0.4440 - accuracy: 0.7980 - val_loss: 0.4249 - val_accuracy: 0.8140\n",
      "Epoch 64/150\n",
      "500/500 - 7s - loss: 0.4460 - accuracy: 0.8020 - val_loss: 0.4126 - val_accuracy: 0.8240\n",
      "Epoch 65/150\n",
      "500/500 - 7s - loss: 0.4161 - accuracy: 0.8220 - val_loss: 0.3965 - val_accuracy: 0.8340\n",
      "Epoch 66/150\n",
      "500/500 - 8s - loss: 0.4059 - accuracy: 0.8340 - val_loss: 0.4119 - val_accuracy: 0.8240\n",
      "Epoch 67/150\n",
      "500/500 - 6s - loss: 0.4197 - accuracy: 0.8320 - val_loss: 0.4116 - val_accuracy: 0.8260\n",
      "Epoch 68/150\n",
      "500/500 - 6s - loss: 0.4005 - accuracy: 0.8340 - val_loss: 0.4256 - val_accuracy: 0.8220\n",
      "Epoch 69/150\n",
      "500/500 - 6s - loss: 0.4241 - accuracy: 0.8060 - val_loss: 0.3995 - val_accuracy: 0.8280\n",
      "Epoch 70/150\n",
      "500/500 - 6s - loss: 0.4174 - accuracy: 0.8100 - val_loss: 0.4488 - val_accuracy: 0.8200\n",
      "Epoch 71/150\n",
      "500/500 - 6s - loss: 0.4685 - accuracy: 0.8140 - val_loss: 0.4732 - val_accuracy: 0.8200\n",
      "Epoch 72/150\n",
      "500/500 - 6s - loss: 0.4229 - accuracy: 0.8160 - val_loss: 0.4076 - val_accuracy: 0.8220\n",
      "Epoch 73/150\n",
      "500/500 - 6s - loss: 0.4263 - accuracy: 0.8220 - val_loss: 0.4194 - val_accuracy: 0.8180\n",
      "Epoch 74/150\n",
      "500/500 - 6s - loss: 0.4339 - accuracy: 0.8160 - val_loss: 0.4056 - val_accuracy: 0.8220\n",
      "Epoch 75/150\n",
      "500/500 - 7s - loss: 0.4445 - accuracy: 0.8100 - val_loss: 0.4082 - val_accuracy: 0.8300\n",
      "Epoch 76/150\n",
      "500/500 - 6s - loss: 0.4011 - accuracy: 0.8240 - val_loss: 0.4089 - val_accuracy: 0.8300\n",
      "Epoch 77/150\n",
      "500/500 - 6s - loss: 0.4045 - accuracy: 0.8320 - val_loss: 0.4055 - val_accuracy: 0.8260\n",
      "Epoch 78/150\n",
      "500/500 - 6s - loss: 0.4215 - accuracy: 0.8180 - val_loss: 0.4050 - val_accuracy: 0.8320\n",
      "Epoch 79/150\n",
      "500/500 - 6s - loss: 0.4279 - accuracy: 0.8280 - val_loss: 0.4177 - val_accuracy: 0.8220\n",
      "Epoch 80/150\n",
      "500/500 - 7s - loss: 0.4335 - accuracy: 0.8060 - val_loss: 0.3998 - val_accuracy: 0.8380\n",
      "Epoch 81/150\n",
      "500/500 - 7s - loss: 0.4192 - accuracy: 0.8180 - val_loss: 0.5088 - val_accuracy: 0.7880\n",
      "Epoch 82/150\n",
      "500/500 - 6s - loss: 0.4740 - accuracy: 0.7940 - val_loss: 0.4531 - val_accuracy: 0.8060\n",
      "Epoch 83/150\n",
      "500/500 - 6s - loss: 0.4324 - accuracy: 0.8200 - val_loss: 0.4061 - val_accuracy: 0.8220\n",
      "Epoch 84/150\n",
      "500/500 - 6s - loss: 0.4105 - accuracy: 0.8240 - val_loss: 0.4130 - val_accuracy: 0.8200\n",
      "Epoch 85/150\n",
      "500/500 - 6s - loss: 0.4099 - accuracy: 0.8160 - val_loss: 0.4095 - val_accuracy: 0.8240\n",
      "Epoch 86/150\n",
      "500/500 - 6s - loss: 0.4160 - accuracy: 0.8220 - val_loss: 0.4117 - val_accuracy: 0.8260\n",
      "Epoch 87/150\n",
      "500/500 - 6s - loss: 0.4633 - accuracy: 0.8160 - val_loss: 0.4466 - val_accuracy: 0.8000\n",
      "Epoch 88/150\n",
      "500/500 - 7s - loss: 0.4526 - accuracy: 0.8220 - val_loss: 0.4322 - val_accuracy: 0.8100\n",
      "Epoch 89/150\n",
      "500/500 - 7s - loss: 0.4380 - accuracy: 0.8100 - val_loss: 0.4490 - val_accuracy: 0.8220\n",
      "Epoch 90/150\n",
      "500/500 - 6s - loss: 0.5074 - accuracy: 0.7780 - val_loss: 0.5094 - val_accuracy: 0.7860\n",
      "Epoch 91/150\n",
      "500/500 - 6s - loss: 0.5145 - accuracy: 0.7880 - val_loss: 0.4159 - val_accuracy: 0.8240\n",
      "Epoch 92/150\n",
      "500/500 - 6s - loss: 0.4831 - accuracy: 0.8020 - val_loss: 0.4246 - val_accuracy: 0.8200\n",
      "Epoch 93/150\n",
      "500/500 - 6s - loss: 0.4188 - accuracy: 0.8180 - val_loss: 0.4345 - val_accuracy: 0.8160\n",
      "Epoch 94/150\n",
      "500/500 - 6s - loss: 0.4072 - accuracy: 0.8340 - val_loss: 0.4983 - val_accuracy: 0.8000\n",
      "Epoch 95/150\n",
      "500/500 - 6s - loss: 0.4307 - accuracy: 0.8160 - val_loss: 0.4012 - val_accuracy: 0.8180\n",
      "Epoch 96/150\n",
      "500/500 - 6s - loss: 0.4758 - accuracy: 0.8140 - val_loss: 0.4005 - val_accuracy: 0.8280\n",
      "Epoch 97/150\n",
      "500/500 - 6s - loss: 0.4194 - accuracy: 0.8140 - val_loss: 0.4057 - val_accuracy: 0.8280\n",
      "Epoch 98/150\n",
      "500/500 - 6s - loss: 0.4025 - accuracy: 0.8320 - val_loss: 0.4253 - val_accuracy: 0.8300\n",
      "Epoch 99/150\n"
     ]
    }
   ],
   "source": [
    "# mlp for the blobs problem with minibatch gradient descent with varied batch size\n",
    "# 아래의 코드에서 다음 두 개의 파라미터를 조합하여 최고의 모델링 성능을 내고 그 결과를 print()로 출력하십시오.\n",
    "# 튜닝할 파라미터 : batch_size & lr (각각 3가지의 옵션이 있으므로 두 파라미터를 조합할 수 있는 경우의 수는 모두 9가지)\n",
    "# 모델의 성능 평가 기준은 다음의 우선순위에 따라 결정하시오. \n",
    "# 1. Validation Loss가 최소, 2. Accuracy는 최고값에 가까울 것\n",
    "# 9번의 실험 후 최적이라고 생각되는 파라미터 값을 코드에 지정하고 셀을 다시 run하여 최종 결과를 출력하시오.\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# prepare train and test dataset\n",
    "def prepare_data():\n",
    "\t# generate 2d classification dataset\n",
    "\tX, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "\t# one hot encode output variable\n",
    "\ty = to_categorical(y)\n",
    "\t# split into train and test\n",
    "\tn_train = 500\n",
    "\ttrainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "\ttrainy, testy = y[:n_train], y[n_train:]\n",
    "\treturn trainX, trainy, testX, testy\n",
    "\n",
    "# fit a model and plot learning curve\n",
    "def fit_model(trainX, trainy, testX, testy, n_batch):\n",
    "\t\n",
    "  # define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(50, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\t\n",
    "  # lr의 값을  0.1, 0.01, 0.001 중에서 선택하여 이곳에 지정\n",
    "\topt = SGD(lr=0.01, momentum=0.9) \n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\t# fit model\n",
    "\thistory = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=150, verbose=2, batch_size=n_batch)\n",
    "\tprint('accuracy = ', format(history.history['accuracy'][149],\".3f\"), ' ', 'validation loss = ', format(history.history['val_loss'][149],\".3f\"))\n",
    "  # plot learning curves\n",
    "\tpyplot.plot(history.history['accuracy'], label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], label='test')\n",
    "\tpyplot.title('batch='+str(n_batch), pad=-40)\n",
    "\n",
    "\n",
    "\n",
    "# prepare dataset\n",
    "trainX, trainy, testX, testy = prepare_data()\n",
    "\n",
    "# batch_size의 값을   16, 32, 64 중에서 선택하여 이곳에 지정\n",
    "batch_size = 64\n",
    "\n",
    "fit_model(trainX, trainy, testX, testy, batch_size)\n",
    "# show learning curves\n",
    "pyplot.show()\n",
    "\n",
    "# 결과를 메모장에 적어놓고 lr과 batch_size를 바꿔가며 최적의 파라미터를 찾아가시오.\n",
    "# 최적의 lr과 batch_size를 선택하여 위의 코드에 적고 Run한 결과룰 출력하여 제출하시오. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hyperparameter-HandTuning .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
